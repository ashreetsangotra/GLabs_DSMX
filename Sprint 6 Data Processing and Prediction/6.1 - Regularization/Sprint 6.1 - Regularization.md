
## SESSION PLAN

### **Session Name**: Regularization

**Learning Outcomes**

-Understand the intuition behind gradient descent
-Understand bias-variance trade-off in data
-Use regularization to get an optimized model
-Apply cross-validation and hyperparameter tuning techniques to further improve the results



**Prerequisites for the Students**

- Regularization- Go through the concept and solve the tasks and assessments.
 
**Student Activities**

- Discuss with the Mentor what you have learned.

- Overview of Regularization
    - Gradient Descent
    - Bias-Variance Trade-off
    - Lasso and Ridge regression
    - Cross-validation and Hyperparameter tuning

- Ask learners How Cross validation help in optimizing the model?
- When and where to choose L1 and L2 regularization?
- What's the relation of bias-variance to overfitting and underfitting?
- Difference between parameters and Hyper-parameters?
- In class Activity


- Questions and Discussion on doubts - AMA

![Session Notebook](https://github.com/commit-live-students/GLabs_DSMX/tree/master/Sprint%206%20Data%20Processing%20and%20Prediction/6.1%20-%20Regularization/notebooks)


**Next Session**

- Concept - EDA and Data Pre-processing
- Key topics to be highlighted - highlight where they would need to spend more time and importance w.r.t Data Science.
    ○ Data Cleaning
    ○ Data Transformation
    ○ Data Exploration




```python

```
